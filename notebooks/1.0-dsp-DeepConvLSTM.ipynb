{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'wget' 不是内部或外部命令，也不是可运行的程序\n",
      "或批处理文件。\n"
     ]
    }
   ],
   "source": [
    "!wget https://archive.ics.uci.edu/ml/machine-learning-databases/00226/OpportunityUCIDataset.zip -P ../data/raw/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-2-05c2b0460174>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-2-05c2b0460174>\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    python3 ../src/data/preprocess_data.py -i  ../data/raw/OpportunityUCIDataset.zip -o ../processed/oppChallenge_gestures.data\u001b[0m\n\u001b[1;37m             ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "!mkdir ../data/processed\n",
    "!python3 ../src/data/preprocess_data.py -i  ../data/raw/OpportunityUCIDataset.zip -o ../processed/oppChallenge_gestures.data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import numpy as np\n",
    "import _pickle as cp\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import sklearn.metrics as metrics\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib\n",
    "matplotlib.use('TkAgg')\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "#NB_SENSOR_CHANNELS = 113\n",
    "NB_SENSOR_CHANNELS = 15\n",
    "SLIDING_WINDOW_LENGTH = 50\n",
    "SLIDING_WINDOW_STEP = 25\n",
    "NB_CLASS = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# add the 'src' directory as one where we can import modules\n",
    "src_dir = os.path.join(os.getcwd(), os.pardir, 'src')\n",
    "sys.path.append(src_dir)\n",
    "\n",
    "from data.sliding_window import sliding_window"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load in Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      " ..from file C:\\Users\\Zhiha\\Documents\\file_only\\research\\tool_program\\ori\\Sensor-Based-Human-Activity-Recognition-DeepConvLSTM-Pytorch\\data\\processed\\mygestures_ww.data\n",
      " ..reading instances: train (60763, 15), test (17422, 15)\n",
      "..part of x_train <class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def load_dataset(filename):\n",
    "    \n",
    "    with open(filename, 'rb') as f:\n",
    "        data = cp.load(f)\n",
    "    \n",
    "    X_train, y_train = data[0]\n",
    "    X_test, y_test = data[1]\n",
    "\n",
    "    print(\" ..from file {}\".format(filename))\n",
    "    print(\" ..reading instances: train {0}, test {1}\".format(X_train.shape, X_test.shape))\n",
    "\n",
    "    X_train = X_train.astype(np.float32)\n",
    "    X_test = X_test.astype(np.float32)\n",
    "    \n",
    "    print(\"..part of x_train\",type(X_train))\n",
    "    #print(X_train[:23,:2])\n",
    "    # The targets are casted to int8 for GPU compatibility.\n",
    "    y_train = y_train.astype(np.uint8)\n",
    "    y_test = y_test.astype(np.uint8)\n",
    "\n",
    "    return X_train, y_train, X_test, y_test\n",
    "\n",
    "print(\"Loading data...\")\n",
    "#X_train, y_train, X_test, y_test = load_dataset('../data/processed/oppChallenge_gestures.data')\n",
    "X_train, y_train, X_test, y_test = load_dataset('C:\\\\Users\\\\Zhiha\\\\Documents\\\\file_only\\\\research\\\\tool_program\\\\ori\\\\Sensor-Based-Human-Activity-Recognition-DeepConvLSTM-Pytorch\\\\data\\\\processed\\\\mygestures_ww.data')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2429, 50, 15)\n",
      " ..after sliding and reshaping, train data: inputs (2429, 50, 15), targets (2429,)\n",
      " ..after sliding and reshaping, test data : inputs (695, 50, 15), targets (695,)\n"
     ]
    }
   ],
   "source": [
    "assert NB_SENSOR_CHANNELS == X_train.shape[1]\n",
    "def opp_sliding_window(data_x, data_y, ws, ss):\n",
    "    data_x = sliding_window(data_x, (ws, data_x.shape[1]), (ss, 1))\n",
    "    data_y = np.asarray([[i[-1]] for i in sliding_window(data_y, ws, ss)])\n",
    "    return data_x.astype(np.float32), data_y.reshape(len(data_y)).astype(np.uint8)\n",
    "\n",
    "# Sensor data is segmented using a sliding window mechanism\n",
    "X_train, y_train = opp_sliding_window(X_train, y_train, SLIDING_WINDOW_LENGTH, SLIDING_WINDOW_STEP)\n",
    "X_test, y_test = opp_sliding_window(X_test, y_test, SLIDING_WINDOW_LENGTH, SLIDING_WINDOW_STEP)\n",
    "#print(X_train[:24,:3])\n",
    "print(X_train.shape)\n",
    "# Data is reshaped\n",
    "X_train = X_train.reshape((-1, SLIDING_WINDOW_LENGTH, NB_SENSOR_CHANNELS)) # for input to Conv1D\n",
    "X_test = X_test.reshape((-1, SLIDING_WINDOW_LENGTH, NB_SENSOR_CHANNELS)) # for input to Conv1D\n",
    "\n",
    "#print(y_train[10:25,])\n",
    "print(\" ..after sliding and reshaping, train data: inputs {0}, targets {1}\".format(X_train.shape, y_train.shape))\n",
    "print(\" ..after sliding and reshaping, test data : inputs {0}, targets {1}\".format(X_test.shape, y_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#='D:\\\\test\\\\project2files\\\\2\\\\files\\\\labels.csv'\n",
    "def return_labels(f,series):\n",
    "    ss = []\n",
    "    df = pd.read_csv(f,header=None)\n",
    "    state = df.iloc[1:,0].to_numpy()\n",
    "    activities = df.iloc[0,1:].to_numpy()\n",
    "    state_len = len(state)\n",
    "    act_len = len(activities)\n",
    "    for s in series:        \n",
    "        x = s % act_len #acts\n",
    "        y = s // act_len #states\n",
    "        #print(state[y]+'+'+activities[x])\n",
    "        ss.append(str(state[y])+'+'+str(activities[x]))\n",
    "    return ss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## draw confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "tick_marks = np.array(range(NB_CLASS)) + 0.5\n",
    "\n",
    "\n",
    "def plot_confusion_matrix(cm, title='Confusion Matrix', cmap=plt.cm.binary):\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    xlocations = np.array(range(NB_CLASS))\n",
    "    plt.xticks(xlocations, xlocations, rotation=90)\n",
    "    plt.yticks(xlocations, xlocations)\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    \n",
    "\n",
    "    \n",
    "def print_cm(cm,epoch):\n",
    "    np.set_printoptions(precision=2)\n",
    "    cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "    print (cm_normalized)\n",
    "    plt.figure(figsize=(12, 8), dpi=120)\n",
    "\n",
    "    ind_array = np.arange(NB_CLASS)\n",
    "    x, y = np.meshgrid(ind_array, ind_array)\n",
    "\n",
    "    for x_val, y_val in zip(x.flatten(), y.flatten()):\n",
    "        c = cm_normalized[y_val][x_val]\n",
    "        if c > 0.01:\n",
    "            plt.text(x_val, y_val, \"%0.2f\" % (c,), color='red', fontsize=7, va='center', ha='center')\n",
    "    # offset the tick\n",
    "    plt.gca().set_xticks(tick_marks, minor=True)\n",
    "    plt.gca().set_yticks(tick_marks, minor=True)\n",
    "    plt.gca().xaxis.set_ticks_position('none')\n",
    "    plt.gca().yaxis.set_ticks_position('none')\n",
    "    plt.grid(True, which='minor', linestyle='-')\n",
    "    plt.gcf().subplots_adjust(bottom=0.15)\n",
    "\n",
    "    plot_confusion_matrix(cm_normalized, title='Normalized confusion matrix')\n",
    "    # show confusion matrix\n",
    "    plt.savefig(os.path.abspath(os.path.join(os.getcwd(), \"..\"))+ '/cm_results/'+'t_matrix'+str(epoch)+'.png', format='png')\n",
    "    plt.close()\n",
    "    #provide report\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HARModel(nn.Module):\n",
    "    \n",
    "    def __init__(self, n_hidden=128, n_layers=1, n_filters=64, \n",
    "                 n_classes=NB_CLASS, filter_size=3, drop_prob=0.5):\n",
    "        super(HARModel, self).__init__()\n",
    "        self.drop_prob = drop_prob\n",
    "        self.n_layers = n_layers\n",
    "        self.n_hidden = n_hidden\n",
    "        self.n_filters = n_filters\n",
    "        self.n_classes = n_classes\n",
    "        self.filter_size = filter_size\n",
    "             \n",
    "        self.conv1 = nn.Conv1d(NB_SENSOR_CHANNELS, n_filters, filter_size)\n",
    "        self.conv2 = nn.Conv1d(n_filters, n_filters, filter_size)\n",
    "        self.conv3 = nn.Conv1d(n_filters, n_filters, filter_size)\n",
    "        self.conv4 = nn.Conv1d(n_filters, n_filters, filter_size)\n",
    "        \n",
    "        self.lstm1  = nn.LSTM(n_filters, n_hidden, n_layers)\n",
    "        self.lstm2  = nn.LSTM(n_hidden, n_hidden, n_layers)\n",
    "        \n",
    "        self.fc = nn.Linear(n_hidden, n_classes)\n",
    "\n",
    "        self.dropout = nn.Dropout(drop_prob)\n",
    "    \n",
    "    def forward(self, x, hidden, batch_size):\n",
    "        #print(x.size())\n",
    "        \n",
    "        #x = x.view(-1, NB_SENSOR_CHANNELS, SLIDING_WINDOW_LENGTH)#reshape\n",
    "        x = x.reshape(-1, NB_SENSOR_CHANNELS, SLIDING_WINDOW_LENGTH)#reshape\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = F.relu(self.conv4(x))\n",
    "        m = x.size()[2]\n",
    "        x = x.view(m, -1, self.n_filters)\n",
    "        x, hidden = self.lstm1(x, hidden)\n",
    "        x, hidden = self.lstm2(x, hidden)\n",
    "        \n",
    "        x = x.contiguous().view(-1, self.n_hidden)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc(x)\n",
    "        \n",
    "        out = x.view(batch_size, -1, self.n_classes)[:,-1,:]\n",
    "        \n",
    "        return out, hidden\n",
    "    \n",
    "    def init_hidden(self, batch_size):\n",
    "        ''' Initializes hidden state '''\n",
    "        # Create two new tensors with sizes n_layers x batch_size x n_hidden,\n",
    "        # initialized to zero, for hidden state and cell state of LSTM\n",
    "        weight = next(self.parameters()).data\n",
    "        '''\n",
    "        if (train_on_gpu):\n",
    "            hidden = (weight.new(self.n_layers, batch_size, self.n_hidden).zero_().cuda(),\n",
    "                  weight.new(self.n_layers, batch_size, self.n_hidden).zero_().cuda())\n",
    "        else:\n",
    "            hidden = (weight.new(self.n_layers, batch_size, self.n_hidden).zero_(),\n",
    "                      weight.new(self.n_layers, batch_size, self.n_hidden).zero_())\n",
    "        '''\n",
    "        hidden = (weight.new(self.n_layers, batch_size, self.n_hidden).zero_(),\n",
    "                      weight.new(self.n_layers, batch_size, self.n_hidden).zero_())\n",
    "        \n",
    "        return hidden\n",
    "    \n",
    "net = HARModel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize Model Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HARModel(\n",
       "  (conv1): Conv1d(15, 64, kernel_size=(3,), stride=(1,))\n",
       "  (conv2): Conv1d(64, 64, kernel_size=(3,), stride=(1,))\n",
       "  (conv3): Conv1d(64, 64, kernel_size=(3,), stride=(1,))\n",
       "  (conv4): Conv1d(64, 64, kernel_size=(3,), stride=(1,))\n",
       "  (lstm1): LSTM(64, 128)\n",
       "  (lstm2): LSTM(128, 128)\n",
       "  (fc): Linear(in_features=128, out_features=4, bias=True)\n",
       "  (dropout): Dropout(p=0.5, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def init_weights(m):\n",
    "    if type(m) == nn.LSTM:\n",
    "        for name, param in m.named_parameters():\n",
    "            if 'weight_ih' in name:\n",
    "                torch.nn.init.orthogonal_(param.data)\n",
    "            elif 'weight_hh' in name:\n",
    "                torch.nn.init.orthogonal_(param.data)\n",
    "            elif 'bias' in name:\n",
    "                param.data.fill_(0)\n",
    "    elif type(m) == nn.Conv1d or type(m) == nn.Linear:\n",
    "        torch.nn.init.orthogonal_(m.weight)\n",
    "        m.bias.data.fill_(0)\n",
    "net.apply(init_weights)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Minibatches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iterate_minibatches(inputs, targets, batchsize, shuffle=True):\n",
    "    assert len(inputs) == len(targets)\n",
    "    if shuffle:\n",
    "        indices = np.arange(len(inputs))\n",
    "        np.random.shuffle(indices)\n",
    "    for start_idx in range(0, len(inputs) - batchsize + 1, batchsize):\n",
    "        if shuffle:\n",
    "            excerpt = indices[start_idx:start_idx + batchsize]\n",
    "        else:\n",
    "            excerpt = slice(start_idx, start_idx + batchsize)\n",
    "        yield inputs[excerpt], targets[excerpt]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "## check if GPU is available\n",
    "#train_on_gpu = torch.cuda.is_available()\n",
    "#if(train_on_gpu):\n",
    "    #print('Training on GPU!')\n",
    "#else: \n",
    "    #print('No GPU available, training on CPU; consider making n_epochs very small.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "Epoch: 1/50... Train Loss: 1.2764... Val Loss: 1.2950... Val Acc: 0.3449... F1-Score: 0.4952...\n",
      "Length of true and predict:690/690...\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "standing+nan       0.00      0.00      0.00       259\n",
      " standing+up       0.00      0.00      0.00        94\n",
      " walking+nan       0.34      1.00      0.51       238\n",
      "  walking+up       0.00      0.00      0.00        99\n",
      "\n",
      "    accuracy                           0.34       690\n",
      "   macro avg       0.09      0.25      0.13       690\n",
      "weighted avg       0.12      0.34      0.18       690\n",
      "\n",
      "save model\n",
      "[[0. 0. 1. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 0. 1. 0.]]\n",
      "10\n",
      "Epoch: 2/50... Train Loss: 1.2663... Val Loss: 1.3052... Val Acc: 0.3377... F1-Score: 0.4793...\n",
      "Length of true and predict:690/690...\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "standing+nan       0.00      0.00      0.00       261\n",
      " standing+up       0.00      0.00      0.00        95\n",
      " walking+nan       0.34      1.00      0.50       233\n",
      "  walking+up       0.00      0.00      0.00       101\n",
      "\n",
      "    accuracy                           0.34       690\n",
      "   macro avg       0.08      0.25      0.13       690\n",
      "weighted avg       0.11      0.34      0.17       690\n",
      "\n",
      "10\n",
      "Epoch: 3/50... Train Loss: 1.2648... Val Loss: 1.2855... Val Acc: 0.3739... F1-Score: 0.5259...\n",
      "Length of true and predict:690/690...\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "standing+nan       0.37      1.00      0.54       258\n",
      " standing+up       0.00      0.00      0.00        94\n",
      " walking+nan       0.00      0.00      0.00       237\n",
      "  walking+up       0.00      0.00      0.00       101\n",
      "\n",
      "    accuracy                           0.37       690\n",
      "   macro avg       0.09      0.25      0.14       690\n",
      "weighted avg       0.14      0.37      0.20       690\n",
      "\n",
      "save model\n",
      "[[1. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]]\n",
      "10\n",
      "Epoch: 4/50... Train Loss: 1.2502... Val Loss: 1.2300... Val Acc: 0.4739... F1-Score: 0.5593...\n",
      "Length of true and predict:690/690...\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "standing+nan       1.00      0.35      0.51       257\n",
      " standing+up       0.00      0.00      0.00        95\n",
      " walking+nan       0.40      1.00      0.57       238\n",
      "  walking+up       0.00      0.00      0.00       100\n",
      "\n",
      "    accuracy                           0.47       690\n",
      "   macro avg       0.35      0.34      0.27       690\n",
      "weighted avg       0.51      0.47      0.39       690\n",
      "\n",
      "save model\n",
      "[[0.35 0.   0.65 0.  ]\n",
      " [0.   0.   1.   0.  ]\n",
      " [0.   0.   1.   0.  ]\n",
      " [0.   0.   1.   0.  ]]\n",
      "10\n",
      "Epoch: 5/50... Train Loss: 0.9890... Val Loss: 0.8350... Val Acc: 0.6435... F1-Score: 0.7239...\n",
      "Length of true and predict:690/690...\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "standing+nan       0.83      0.93      0.88       260\n",
      " standing+up       0.00      0.00      0.00        95\n",
      " walking+nan       0.51      0.86      0.64       234\n",
      "  walking+up       0.00      0.00      0.00       101\n",
      "\n",
      "    accuracy                           0.64       690\n",
      "   macro avg       0.33      0.45      0.38       690\n",
      "weighted avg       0.49      0.64      0.55       690\n",
      "\n",
      "save model\n",
      "[[0.93 0.   0.07 0.  ]\n",
      " [0.05 0.   0.95 0.  ]\n",
      " [0.14 0.   0.86 0.  ]\n",
      " [0.12 0.   0.88 0.  ]]\n",
      "10\n",
      "Epoch: 6/50... Train Loss: 0.8066... Val Loss: 0.5926... Val Acc: 0.7420... F1-Score: 0.7674...\n",
      "Length of true and predict:690/690...\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "standing+nan       0.97      0.79      0.87       260\n",
      " standing+up       0.00      0.00      0.00        94\n",
      " walking+nan       0.74      0.96      0.83       236\n",
      "  walking+up       0.47      0.80      0.59       100\n",
      "\n",
      "    accuracy                           0.74       690\n",
      "   macro avg       0.54      0.64      0.57       690\n",
      "weighted avg       0.69      0.74      0.70       690\n",
      "\n",
      "save model\n",
      "[[0.79 0.   0.2  0.01]\n",
      " [0.   0.   0.1  0.9 ]\n",
      " [0.03 0.   0.96 0.01]\n",
      " [0.   0.   0.2  0.8 ]]\n",
      "10\n",
      "Epoch: 7/50... Train Loss: 0.5299... Val Loss: 0.4365... Val Acc: 0.7696... F1-Score: 0.7897...\n",
      "Length of true and predict:690/690...\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "standing+nan       0.97      0.86      0.91       259\n",
      " standing+up       0.45      0.05      0.10        94\n",
      " walking+nan       0.80      0.97      0.87       236\n",
      "  walking+up       0.47      0.75      0.58       101\n",
      "\n",
      "    accuracy                           0.77       690\n",
      "   macro avg       0.67      0.66      0.61       690\n",
      "weighted avg       0.77      0.77      0.74       690\n",
      "\n",
      "save model\n",
      "[[0.86 0.   0.14 0.01]\n",
      " [0.01 0.05 0.05 0.88]\n",
      " [0.03 0.   0.97 0.01]\n",
      " [0.01 0.06 0.18 0.75]]\n",
      "10\n",
      "Epoch: 8/50... Train Loss: 0.4487... Val Loss: 0.3436... Val Acc: 0.8232... F1-Score: 0.8483...\n",
      "Length of true and predict:690/690...\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "standing+nan       0.96      0.96      0.96       260\n",
      " standing+up       0.00      0.00      0.00        94\n",
      " walking+nan       0.94      0.94      0.94       235\n",
      "  walking+up       0.49      0.96      0.65       101\n",
      "\n",
      "    accuracy                           0.82       690\n",
      "   macro avg       0.60      0.72      0.64       690\n",
      "weighted avg       0.76      0.82      0.78       690\n",
      "\n",
      "save model\n",
      "[[0.96 0.   0.03 0.01]\n",
      " [0.   0.   0.   1.  ]\n",
      " [0.04 0.   0.94 0.01]\n",
      " [0.   0.   0.04 0.96]]\n",
      "10\n",
      "Epoch: 9/50... Train Loss: 0.3881... Val Loss: 0.3574... Val Acc: 0.8420... F1-Score: 0.8459...\n",
      "Length of true and predict:690/690...\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "standing+nan       0.97      0.93      0.95       259\n",
      " standing+up       0.69      0.35      0.46        95\n",
      " walking+nan       0.93      0.96      0.94       236\n",
      "  walking+up       0.54      0.81      0.65       100\n",
      "\n",
      "    accuracy                           0.84       690\n",
      "   macro avg       0.78      0.76      0.75       690\n",
      "weighted avg       0.85      0.84      0.84       690\n",
      "\n",
      "save model\n",
      "[[0.93 0.   0.05 0.03]\n",
      " [0.   0.35 0.02 0.63]\n",
      " [0.03 0.   0.96 0.01]\n",
      " [0.   0.15 0.04 0.81]]\n",
      "10\n",
      "Epoch: 10/50... Train Loss: 0.3447... Val Loss: 0.3300... Val Acc: 0.8449... F1-Score: 0.8606...\n",
      "Length of true and predict:690/690...\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "standing+nan       0.98      0.94      0.96       260\n",
      " standing+up       0.76      0.28      0.41        92\n",
      " walking+nan       0.89      0.99      0.94       237\n",
      "  walking+up       0.55      0.78      0.64       101\n",
      "\n",
      "    accuracy                           0.84       690\n",
      "   macro avg       0.80      0.75      0.74       690\n",
      "weighted avg       0.86      0.84      0.83       690\n",
      "\n",
      "save model\n",
      "[[0.94 0.   0.05 0.01]\n",
      " [0.   0.28 0.03 0.68]\n",
      " [0.01 0.   0.99 0.  ]\n",
      " [0.03 0.08 0.11 0.78]]\n",
      "10\n",
      "Epoch: 11/50... Train Loss: 0.3088... Val Loss: 0.3216... Val Acc: 0.8594... F1-Score: 0.8701...\n",
      "Length of true and predict:690/690...\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "standing+nan       0.90      0.99      0.94       258\n",
      " standing+up       0.77      0.53      0.62        95\n",
      " walking+nan       0.97      0.89      0.93       236\n",
      "  walking+up       0.62      0.77      0.69       101\n",
      "\n",
      "    accuracy                           0.86       690\n",
      "   macro avg       0.82      0.79      0.80       690\n",
      "weighted avg       0.87      0.86      0.86       690\n",
      "\n",
      "save model\n",
      "[[0.99 0.   0.   0.01]\n",
      " [0.   0.53 0.   0.47]\n",
      " [0.11 0.   0.89 0.  ]\n",
      " [0.02 0.15 0.06 0.77]]\n",
      "10\n",
      "Epoch: 12/50... Train Loss: 0.2892... Val Loss: 0.3648... Val Acc: 0.8217... F1-Score: 0.8479...\n",
      "Length of true and predict:690/690...\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "standing+nan       0.98      0.96      0.97       260\n",
      " standing+up       0.00      0.00      0.00        94\n",
      " walking+nan       0.91      0.98      0.94       237\n",
      "  walking+up       0.47      0.85      0.61        99\n",
      "\n",
      "    accuracy                           0.82       690\n",
      "   macro avg       0.59      0.70      0.63       690\n",
      "weighted avg       0.75      0.82      0.78       690\n",
      "\n",
      "10\n",
      "Epoch: 13/50... Train Loss: 0.2661... Val Loss: 0.2881... Val Acc: 0.8725... F1-Score: 0.8789...\n",
      "Length of true and predict:690/690...\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "standing+nan       0.97      0.96      0.97       259\n",
      " standing+up       0.86      0.39      0.54        94\n",
      " walking+nan       0.95      0.97      0.96       238\n",
      "  walking+up       0.57      0.86      0.69        99\n",
      "\n",
      "    accuracy                           0.87       690\n",
      "   macro avg       0.84      0.80      0.79       690\n",
      "weighted avg       0.89      0.87      0.87       690\n",
      "\n",
      "save model\n",
      "[[0.96 0.   0.01 0.03]\n",
      " [0.   0.39 0.01 0.6 ]\n",
      " [0.03 0.   0.97 0.  ]\n",
      " [0.01 0.06 0.07 0.86]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "Epoch: 14/50... Train Loss: 0.2471... Val Loss: 0.2441... Val Acc: 0.9203... F1-Score: 0.9219...\n",
      "Length of true and predict:690/690...\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "standing+nan       0.96      0.97      0.97       258\n",
      " standing+up       0.76      0.95      0.84        94\n",
      " walking+nan       0.97      0.96      0.97       237\n",
      "  walking+up       0.87      0.67      0.76       101\n",
      "\n",
      "    accuracy                           0.92       690\n",
      "   macro avg       0.89      0.89      0.88       690\n",
      "weighted avg       0.92      0.92      0.92       690\n",
      "\n",
      "save model\n",
      "[[0.97 0.   0.01 0.02]\n",
      " [0.   0.95 0.   0.05]\n",
      " [0.04 0.   0.96 0.  ]\n",
      " [0.01 0.28 0.04 0.67]]\n",
      "10\n",
      "Epoch: 15/50... Train Loss: 0.2203... Val Loss: 0.2289... Val Acc: 0.9101... F1-Score: 0.9131...\n",
      "Length of true and predict:690/690...\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "standing+nan       0.97      0.98      0.97       259\n",
      " standing+up       0.69      0.95      0.80        95\n",
      " walking+nan       0.98      0.97      0.97       235\n",
      "  walking+up       0.87      0.57      0.69       101\n",
      "\n",
      "    accuracy                           0.91       690\n",
      "   macro avg       0.88      0.87      0.86       690\n",
      "weighted avg       0.92      0.91      0.91       690\n",
      "\n",
      "save model\n",
      "[[0.98 0.   0.01 0.01]\n",
      " [0.   0.95 0.   0.05]\n",
      " [0.03 0.   0.97 0.  ]\n",
      " [0.   0.41 0.02 0.57]]\n",
      "10\n",
      "Epoch: 16/50... Train Loss: 0.1919... Val Loss: 0.2414... Val Acc: 0.8928... F1-Score: 0.8928...\n",
      "Length of true and predict:690/690...\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "standing+nan       0.98      0.96      0.97       258\n",
      " standing+up       0.72      0.69      0.71        95\n",
      " walking+nan       0.96      0.97      0.97       237\n",
      "  walking+up       0.68      0.72      0.70       100\n",
      "\n",
      "    accuracy                           0.89       690\n",
      "   macro avg       0.83      0.84      0.84       690\n",
      "weighted avg       0.89      0.89      0.89       690\n",
      "\n",
      "10\n",
      "Epoch: 17/50... Train Loss: 0.1758... Val Loss: 0.3029... Val Acc: 0.8812... F1-Score: 0.8930...\n",
      "Length of true and predict:690/690...\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "standing+nan       0.97      0.98      0.97       259\n",
      " standing+up       0.84      0.40      0.54        93\n",
      " walking+nan       0.97      0.97      0.97       237\n",
      "  walking+up       0.60      0.86      0.71       101\n",
      "\n",
      "    accuracy                           0.88       690\n",
      "   macro avg       0.84      0.80      0.80       690\n",
      "weighted avg       0.90      0.88      0.87       690\n",
      "\n",
      "10\n",
      "Epoch: 18/50... Train Loss: 0.1597... Val Loss: 0.3774... Val Acc: 0.8551... F1-Score: 0.8689...\n",
      "Length of true and predict:690/690...\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "standing+nan       0.93      0.98      0.95       259\n",
      " standing+up       0.88      0.30      0.45        93\n",
      " walking+nan       0.99      0.92      0.95       237\n",
      "  walking+up       0.55      0.89      0.68       101\n",
      "\n",
      "    accuracy                           0.86       690\n",
      "   macro avg       0.84      0.77      0.76       690\n",
      "weighted avg       0.89      0.86      0.84       690\n",
      "\n",
      "10\n",
      "Epoch: 19/50... Train Loss: 0.1772... Val Loss: 0.2578... Val Acc: 0.8928... F1-Score: 0.8911...\n",
      "Length of true and predict:690/690...\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "standing+nan       0.95      0.97      0.96       259\n",
      " standing+up       0.85      0.60      0.70        94\n",
      " walking+nan       0.97      0.95      0.96       237\n",
      "  walking+up       0.66      0.86      0.74       100\n",
      "\n",
      "    accuracy                           0.89       690\n",
      "   macro avg       0.86      0.84      0.84       690\n",
      "weighted avg       0.90      0.89      0.89       690\n",
      "\n",
      "10\n",
      "Epoch: 20/50... Train Loss: 0.1578... Val Loss: 0.3099... Val Acc: 0.8725... F1-Score: 0.8708...\n",
      "Length of true and predict:690/690...\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "standing+nan       0.96      0.91      0.93       260\n",
      " standing+up       0.75      0.73      0.74        95\n",
      " walking+nan       0.92      0.96      0.94       235\n",
      "  walking+up       0.67      0.70      0.68       100\n",
      "\n",
      "    accuracy                           0.87       690\n",
      "   macro avg       0.82      0.82      0.82       690\n",
      "weighted avg       0.87      0.87      0.87       690\n",
      "\n",
      "10\n",
      "Epoch: 21/50... Train Loss: 0.1496... Val Loss: 0.2974... Val Acc: 0.8986... F1-Score: 0.9015...\n",
      "Length of true and predict:690/690...\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "standing+nan       0.96      0.95      0.96       259\n",
      " standing+up       0.84      0.65      0.73        95\n",
      " walking+nan       0.95      0.96      0.96       235\n",
      "  walking+up       0.70      0.85      0.77       101\n",
      "\n",
      "    accuracy                           0.90       690\n",
      "   macro avg       0.86      0.85      0.85       690\n",
      "weighted avg       0.90      0.90      0.90       690\n",
      "\n",
      "10\n",
      "Epoch: 22/50... Train Loss: 0.1336... Val Loss: 0.3085... Val Acc: 0.8768... F1-Score: 0.8819...\n",
      "Length of true and predict:690/690...\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "standing+nan       0.97      0.92      0.94       260\n",
      " standing+up       0.92      0.47      0.62        93\n",
      " walking+nan       0.95      0.97      0.96       237\n",
      "  walking+up       0.60      0.91      0.72       100\n",
      "\n",
      "    accuracy                           0.88       690\n",
      "   macro avg       0.86      0.82      0.81       690\n",
      "weighted avg       0.90      0.88      0.87       690\n",
      "\n",
      "10\n",
      "Epoch: 23/50... Train Loss: 0.1301... Val Loss: 0.2807... Val Acc: 0.8899... F1-Score: 0.8892...\n",
      "Length of true and predict:690/690...\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "standing+nan       0.98      0.92      0.95       257\n",
      " standing+up       0.75      0.76      0.75        95\n",
      " walking+nan       0.92      0.98      0.95       237\n",
      "  walking+up       0.72      0.72      0.72       101\n",
      "\n",
      "    accuracy                           0.89       690\n",
      "   macro avg       0.84      0.85      0.84       690\n",
      "weighted avg       0.89      0.89      0.89       690\n",
      "\n",
      "10\n",
      "Epoch: 24/50... Train Loss: 0.1020... Val Loss: 0.3543... Val Acc: 0.8710... F1-Score: 0.8823...\n",
      "Length of true and predict:690/690...\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "standing+nan       0.96      0.97      0.96       258\n",
      " standing+up       0.92      0.35      0.50        95\n",
      " walking+nan       0.97      0.96      0.96       238\n",
      "  walking+up       0.58      0.92      0.71        99\n",
      "\n",
      "    accuracy                           0.87       690\n",
      "   macro avg       0.85      0.80      0.78       690\n",
      "weighted avg       0.90      0.87      0.86       690\n",
      "\n",
      "10\n",
      "Epoch: 25/50... Train Loss: 0.1052... Val Loss: 0.2114... Val Acc: 0.9217... F1-Score: 0.9245...\n",
      "Length of true and predict:690/690...\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "standing+nan       0.97      0.96      0.96       260\n",
      " standing+up       0.82      0.84      0.83        93\n",
      " walking+nan       0.97      0.97      0.97       236\n",
      "  walking+up       0.80      0.79      0.80       101\n",
      "\n",
      "    accuracy                           0.92       690\n",
      "   macro avg       0.89      0.89      0.89       690\n",
      "weighted avg       0.92      0.92      0.92       690\n",
      "\n",
      "save model\n",
      "[[0.96 0.   0.02 0.02]\n",
      " [0.   0.84 0.   0.16]\n",
      " [0.03 0.   0.97 0.  ]\n",
      " [0.01 0.17 0.03 0.79]]\n",
      "10\n",
      "Epoch: 26/50... Train Loss: 0.0976... Val Loss: 0.2597... Val Acc: 0.9072... F1-Score: 0.9119...\n",
      "Length of true and predict:690/690...\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "standing+nan       0.98      0.95      0.96       257\n",
      " standing+up       0.83      0.68      0.75        95\n",
      " walking+nan       0.95      0.98      0.96       237\n",
      "  walking+up       0.72      0.83      0.77       101\n",
      "\n",
      "    accuracy                           0.91       690\n",
      "   macro avg       0.87      0.86      0.86       690\n",
      "weighted avg       0.91      0.91      0.91       690\n",
      "\n",
      "10\n",
      "Epoch: 27/50... Train Loss: 0.0989... Val Loss: 0.2727... Val Acc: 0.8928... F1-Score: 0.8948...\n",
      "Length of true and predict:690/690...\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "standing+nan       0.97      0.97      0.97       259\n",
      " standing+up       0.69      0.77      0.73        93\n",
      " walking+nan       0.96      0.97      0.96       238\n",
      "  walking+up       0.72      0.63      0.67       100\n",
      "\n",
      "    accuracy                           0.89       690\n",
      "   macro avg       0.84      0.83      0.83       690\n",
      "weighted avg       0.89      0.89      0.89       690\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "Epoch: 28/50... Train Loss: 0.1021... Val Loss: 0.3095... Val Acc: 0.8986... F1-Score: 0.8920...\n",
      "Length of true and predict:690/690...\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "standing+nan       0.99      0.92      0.95       259\n",
      " standing+up       0.82      0.73      0.78        94\n",
      " walking+nan       0.95      0.97      0.96       238\n",
      "  walking+up       0.67      0.84      0.74        99\n",
      "\n",
      "    accuracy                           0.90       690\n",
      "   macro avg       0.86      0.86      0.86       690\n",
      "weighted avg       0.91      0.90      0.90       690\n",
      "\n",
      "10\n",
      "Epoch: 29/50... Train Loss: 0.0977... Val Loss: 0.2616... Val Acc: 0.8971... F1-Score: 0.8999...\n",
      "Length of true and predict:690/690...\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "standing+nan       0.97      0.98      0.97       261\n",
      " standing+up       0.75      0.69      0.72        93\n",
      " walking+nan       0.95      0.97      0.96       237\n",
      "  walking+up       0.70      0.72      0.71        99\n",
      "\n",
      "    accuracy                           0.90       690\n",
      "   macro avg       0.84      0.84      0.84       690\n",
      "weighted avg       0.90      0.90      0.90       690\n",
      "\n",
      "10\n",
      "Epoch: 30/50... Train Loss: 0.0812... Val Loss: 0.3709... Val Acc: 0.8696... F1-Score: 0.8660...\n",
      "Length of true and predict:690/690...\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "standing+nan       0.96      0.94      0.95       258\n",
      " standing+up       0.70      0.63      0.66        95\n",
      " walking+nan       0.93      0.96      0.95       237\n",
      "  walking+up       0.65      0.71      0.68       100\n",
      "\n",
      "    accuracy                           0.87       690\n",
      "   macro avg       0.81      0.81      0.81       690\n",
      "weighted avg       0.87      0.87      0.87       690\n",
      "\n",
      "10\n",
      "Epoch: 31/50... Train Loss: 0.0862... Val Loss: 0.2168... Val Acc: 0.9087... F1-Score: 0.9079...\n",
      "Length of true and predict:690/690...\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "standing+nan       0.98      0.95      0.96       259\n",
      " standing+up       0.75      0.82      0.78        95\n",
      " walking+nan       0.95      0.98      0.97       236\n",
      "  walking+up       0.78      0.71      0.74       100\n",
      "\n",
      "    accuracy                           0.91       690\n",
      "   macro avg       0.87      0.87      0.86       690\n",
      "weighted avg       0.91      0.91      0.91       690\n",
      "\n",
      "10\n",
      "Epoch: 32/50... Train Loss: 0.0664... Val Loss: 0.4317... Val Acc: 0.8812... F1-Score: 0.8914...\n",
      "Length of true and predict:690/690...\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "standing+nan       0.96      0.97      0.96       259\n",
      " standing+up       0.92      0.38      0.54        95\n",
      " walking+nan       0.97      0.96      0.97       237\n",
      "  walking+up       0.60      0.94      0.73        99\n",
      "\n",
      "    accuracy                           0.88       690\n",
      "   macro avg       0.86      0.81      0.80       690\n",
      "weighted avg       0.91      0.88      0.87       690\n",
      "\n",
      "10\n",
      "Epoch: 33/50... Train Loss: 0.0613... Val Loss: 0.2590... Val Acc: 0.9130... F1-Score: 0.9110...\n",
      "Length of true and predict:690/690...\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "standing+nan       0.97      0.97      0.97       260\n",
      " standing+up       0.77      0.80      0.78        95\n",
      " walking+nan       0.97      0.97      0.97       236\n",
      "  walking+up       0.78      0.74      0.76        99\n",
      "\n",
      "    accuracy                           0.91       690\n",
      "   macro avg       0.87      0.87      0.87       690\n",
      "weighted avg       0.91      0.91      0.91       690\n",
      "\n",
      "10\n",
      "Epoch: 34/50... Train Loss: 0.0730... Val Loss: 0.3412... Val Acc: 0.8971... F1-Score: 0.8995...\n",
      "Length of true and predict:690/690...\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "standing+nan       0.94      0.98      0.96       259\n",
      " standing+up       0.81      0.66      0.73        94\n",
      " walking+nan       0.97      0.94      0.95       236\n",
      "  walking+up       0.71      0.80      0.75       101\n",
      "\n",
      "    accuracy                           0.90       690\n",
      "   macro avg       0.86      0.85      0.85       690\n",
      "weighted avg       0.90      0.90      0.90       690\n",
      "\n",
      "10\n",
      "Epoch: 35/50... Train Loss: 0.0718... Val Loss: 0.2671... Val Acc: 0.9217... F1-Score: 0.9263...\n",
      "Length of true and predict:690/690...\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "standing+nan       0.97      0.97      0.97       260\n",
      " standing+up       0.94      0.68      0.79        94\n",
      " walking+nan       0.96      0.97      0.97       236\n",
      "  walking+up       0.74      0.92      0.82       100\n",
      "\n",
      "    accuracy                           0.92       690\n",
      "   macro avg       0.90      0.88      0.89       690\n",
      "weighted avg       0.93      0.92      0.92       690\n",
      "\n",
      "save model\n",
      "[[0.97 0.   0.02 0.02]\n",
      " [0.   0.68 0.02 0.3 ]\n",
      " [0.03 0.   0.97 0.  ]\n",
      " [0.02 0.04 0.02 0.92]]\n",
      "10\n",
      "Epoch: 36/50... Train Loss: 0.0550... Val Loss: 0.3210... Val Acc: 0.9000... F1-Score: 0.9021...\n",
      "Length of true and predict:690/690...\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "standing+nan       0.97      0.96      0.96       261\n",
      " standing+up       0.82      0.64      0.72        94\n",
      " walking+nan       0.96      0.96      0.96       236\n",
      "  walking+up       0.68      0.85      0.76        99\n",
      "\n",
      "    accuracy                           0.90       690\n",
      "   macro avg       0.86      0.85      0.85       690\n",
      "weighted avg       0.91      0.90      0.90       690\n",
      "\n",
      "10\n",
      "Epoch: 37/50... Train Loss: 0.0729... Val Loss: 0.3413... Val Acc: 0.8957... F1-Score: 0.8947...\n",
      "Length of true and predict:690/690...\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "standing+nan       0.96      0.95      0.96       258\n",
      " standing+up       0.71      0.81      0.75        93\n",
      " walking+nan       0.98      0.95      0.96       238\n",
      "  walking+up       0.73      0.71      0.72       101\n",
      "\n",
      "    accuracy                           0.90       690\n",
      "   macro avg       0.85      0.85      0.85       690\n",
      "weighted avg       0.90      0.90      0.90       690\n",
      "\n",
      "10\n",
      "Epoch: 38/50... Train Loss: 0.0560... Val Loss: 0.3623... Val Acc: 0.8884... F1-Score: 0.8973...\n",
      "Length of true and predict:690/690...\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "standing+nan       0.96      0.97      0.96       259\n",
      " standing+up       0.91      0.51      0.65        95\n",
      " walking+nan       0.95      0.96      0.95       237\n",
      "  walking+up       0.64      0.88      0.74        99\n",
      "\n",
      "    accuracy                           0.89       690\n",
      "   macro avg       0.86      0.83      0.83       690\n",
      "weighted avg       0.90      0.89      0.88       690\n",
      "\n",
      "10\n",
      "Epoch: 39/50... Train Loss: 0.0261... Val Loss: 0.3678... Val Acc: 0.9072... F1-Score: 0.9080...\n",
      "Length of true and predict:690/690...\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "standing+nan       0.95      0.98      0.97       259\n",
      " standing+up       0.87      0.65      0.74        94\n",
      " walking+nan       0.97      0.96      0.96       237\n",
      "  walking+up       0.71      0.84      0.77       100\n",
      "\n",
      "    accuracy                           0.91       690\n",
      "   macro avg       0.87      0.86      0.86       690\n",
      "weighted avg       0.91      0.91      0.91       690\n",
      "\n",
      "10\n",
      "Epoch: 40/50... Train Loss: 0.0832... Val Loss: 0.3036... Val Acc: 0.9043... F1-Score: 0.9042...\n",
      "Length of true and predict:690/690...\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "standing+nan       0.97      0.95      0.96       260\n",
      " standing+up       0.79      0.73      0.76        94\n",
      " walking+nan       0.95      0.97      0.96       235\n",
      "  walking+up       0.74      0.80      0.77       101\n",
      "\n",
      "    accuracy                           0.90       690\n",
      "   macro avg       0.86      0.86      0.86       690\n",
      "weighted avg       0.91      0.90      0.90       690\n",
      "\n",
      "10\n",
      "Epoch: 41/50... Train Loss: 0.0575... Val Loss: 0.4801... Val Acc: 0.8783... F1-Score: 0.8831...\n",
      "Length of true and predict:690/690...\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "standing+nan       0.94      0.98      0.96       260\n",
      " standing+up       0.83      0.46      0.59        94\n",
      " walking+nan       0.97      0.95      0.96       236\n",
      "  walking+up       0.61      0.84      0.71       100\n",
      "\n",
      "    accuracy                           0.88       690\n",
      "   macro avg       0.84      0.81      0.80       690\n",
      "weighted avg       0.89      0.88      0.87       690\n",
      "\n",
      "10\n",
      "Epoch: 42/50... Train Loss: 0.0423... Val Loss: 0.2942... Val Acc: 0.9217... F1-Score: 0.9243...\n",
      "Length of true and predict:690/690...\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "standing+nan       0.97      0.95      0.96       260\n",
      " standing+up       0.79      0.88      0.83        92\n",
      " walking+nan       0.95      0.97      0.96       237\n",
      "  walking+up       0.84      0.75      0.80       101\n",
      "\n",
      "    accuracy                           0.92       690\n",
      "   macro avg       0.89      0.89      0.89       690\n",
      "weighted avg       0.92      0.92      0.92       690\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "Epoch: 43/50... Train Loss: 0.0454... Val Loss: 0.3382... Val Acc: 0.9072... F1-Score: 0.9106...\n",
      "Length of true and predict:690/690...\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "standing+nan       0.96      0.96      0.96       260\n",
      " standing+up       0.87      0.71      0.78        95\n",
      " walking+nan       0.94      0.96      0.95       236\n",
      "  walking+up       0.73      0.84      0.78        99\n",
      "\n",
      "    accuracy                           0.91       690\n",
      "   macro avg       0.88      0.87      0.87       690\n",
      "weighted avg       0.91      0.91      0.91       690\n",
      "\n",
      "10\n",
      "Epoch: 44/50... Train Loss: 0.0440... Val Loss: 0.2898... Val Acc: 0.9087... F1-Score: 0.9093...\n",
      "Length of true and predict:690/690...\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "standing+nan       0.96      0.95      0.96       259\n",
      " standing+up       0.79      0.81      0.80        95\n",
      " walking+nan       0.96      0.96      0.96       236\n",
      "  walking+up       0.76      0.76      0.76       100\n",
      "\n",
      "    accuracy                           0.91       690\n",
      "   macro avg       0.87      0.87      0.87       690\n",
      "weighted avg       0.91      0.91      0.91       690\n",
      "\n",
      "10\n",
      "Epoch: 45/50... Train Loss: 0.0159... Val Loss: 0.3519... Val Acc: 0.9072... F1-Score: 0.9098...\n",
      "Length of true and predict:690/690...\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "standing+nan       0.96      0.96      0.96       260\n",
      " standing+up       0.75      0.89      0.82        94\n",
      " walking+nan       0.95      0.96      0.95       236\n",
      "  walking+up       0.85      0.66      0.74       100\n",
      "\n",
      "    accuracy                           0.91       690\n",
      "   macro avg       0.87      0.87      0.87       690\n",
      "weighted avg       0.91      0.91      0.91       690\n",
      "\n",
      "10\n",
      "Epoch: 46/50... Train Loss: 0.0428... Val Loss: 0.3110... Val Acc: 0.9130... F1-Score: 0.9136...\n",
      "Length of true and predict:690/690...\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "standing+nan       0.97      0.97      0.97       259\n",
      " standing+up       0.90      0.65      0.76        95\n",
      " walking+nan       0.96      0.97      0.96       235\n",
      "  walking+up       0.73      0.89      0.80       101\n",
      "\n",
      "    accuracy                           0.91       690\n",
      "   macro avg       0.89      0.87      0.87       690\n",
      "weighted avg       0.92      0.91      0.91       690\n",
      "\n",
      "10\n",
      "Epoch: 47/50... Train Loss: 0.0097... Val Loss: 0.3082... Val Acc: 0.9246... F1-Score: 0.9253...\n",
      "Length of true and predict:690/690...\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "standing+nan       0.97      0.97      0.97       260\n",
      " standing+up       0.85      0.81      0.83        94\n",
      " walking+nan       0.96      0.97      0.96       236\n",
      "  walking+up       0.80      0.83      0.81       100\n",
      "\n",
      "    accuracy                           0.92       690\n",
      "   macro avg       0.89      0.89      0.89       690\n",
      "weighted avg       0.92      0.92      0.92       690\n",
      "\n",
      "save model\n",
      "[[0.97 0.   0.02 0.01]\n",
      " [0.   0.81 0.   0.19]\n",
      " [0.03 0.   0.97 0.  ]\n",
      " [0.01 0.13 0.03 0.83]]\n",
      "10\n",
      "Epoch: 48/50... Train Loss: 0.0079... Val Loss: 0.3646... Val Acc: 0.9203... F1-Score: 0.9147...\n",
      "Length of true and predict:690/690...\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "standing+nan       0.97      0.97      0.97       259\n",
      " standing+up       0.88      0.73      0.80        93\n",
      " walking+nan       0.96      0.97      0.96       237\n",
      "  walking+up       0.76      0.87      0.81       101\n",
      "\n",
      "    accuracy                           0.92       690\n",
      "   macro avg       0.89      0.88      0.89       690\n",
      "weighted avg       0.92      0.92      0.92       690\n",
      "\n",
      "10\n",
      "Epoch: 49/50... Train Loss: 0.0046... Val Loss: 0.4122... Val Acc: 0.9174... F1-Score: 0.9204...\n",
      "Length of true and predict:690/690...\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "standing+nan       0.96      0.97      0.96       261\n",
      " standing+up       0.87      0.73      0.80        94\n",
      " walking+nan       0.96      0.96      0.96       235\n",
      "  walking+up       0.75      0.86      0.80       100\n",
      "\n",
      "    accuracy                           0.92       690\n",
      "   macro avg       0.89      0.88      0.88       690\n",
      "weighted avg       0.92      0.92      0.92       690\n",
      "\n",
      "10\n",
      "Epoch: 50/50... Train Loss: 0.0227... Val Loss: 0.5986... Val Acc: 0.8667... F1-Score: 0.8679...\n",
      "Length of true and predict:690/690...\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "standing+nan       0.95      0.95      0.95       259\n",
      " standing+up       0.71      0.55      0.62        95\n",
      " walking+nan       0.97      0.94      0.96       236\n",
      "  walking+up       0.60      0.77      0.68       100\n",
      "\n",
      "    accuracy                           0.87       690\n",
      "   macro avg       0.81      0.80      0.80       690\n",
      "weighted avg       0.87      0.87      0.87       690\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def train(net, epochs=50, batch_size=10, lr=0.01):\n",
    "    min_loss = 100\n",
    "    max_acc = 0.1\n",
    "    opt = torch.optim.SGD(net.parameters(), lr=lr, momentum=0.9, weight_decay=1e-4)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    #if(train_on_gpu):\n",
    "        #net.cuda()\n",
    "    valloss =[]\n",
    "    valacc = []\n",
    "    traloss =[]\n",
    "    t = np.arange(NB_CLASS)\n",
    "    y_unique = return_labels('D:\\\\test\\\\project2files\\\\2\\\\test\\\\files\\\\labels.csv',t)\n",
    "    for e in range(epochs):\n",
    "        \n",
    "        # initialize hidden state\n",
    "        h = net.init_hidden(batch_size)         \n",
    "        train_losses = []    \n",
    "        net.train()\n",
    "        for batch in iterate_minibatches(X_train, y_train, batch_size):\n",
    "            x, y = batch\n",
    "\n",
    "            inputs, targets = torch.from_numpy(x), torch.from_numpy(y)\n",
    "            \n",
    "\n",
    "            #if(train_on_gpu):\n",
    "            #        inputs, targets = inputs.cuda(), targets.cuda()\n",
    "\n",
    "            # Creating new variables for the hidden state, otherwise\n",
    "            # we'd backprop through the entire training history\n",
    "            h = tuple([each.data for each in h])\n",
    "            \n",
    "            # zero accumulated gradients\n",
    "            opt.zero_grad()   \n",
    "            \n",
    "            # get the output from the model\n",
    "            output, h = net(inputs, h, batch_size)\n",
    "            \n",
    "            loss = criterion(output, targets.long())\n",
    "            train_losses.append(loss.item())\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "            \n",
    "        val_h = net.init_hidden(batch_size)\n",
    "        val_losses = []\n",
    "        ##\n",
    "        val_output = []\n",
    "        val_target = []\n",
    "        ##\n",
    "        accuracy=0\n",
    "        f1score=0\n",
    "        net.eval()\n",
    "        with torch.no_grad():\n",
    "            for batch in iterate_minibatches(X_test, y_test, batch_size):\n",
    "                x, y = batch     \n",
    "                val_target.extend(y)\n",
    "                inputs, targets = torch.from_numpy(x), torch.from_numpy(y)\n",
    "                #print(\"targets: \\n\",targets)\n",
    "                #val_target.extend(targets)\n",
    "                \n",
    "\n",
    "                val_h = tuple([each.data for each in val_h])\n",
    "\n",
    "                #if(train_on_gpu):\n",
    "                #    inputs, targets = inputs.cuda(), targets.cuda()\n",
    "                    \n",
    "                output, val_h= net(inputs, val_h, batch_size)\n",
    "                #print(\"output: \\n\",output)\n",
    "                #val_output.extend(output)\n",
    "\n",
    "                val_loss = criterion(output, targets.long())\n",
    "                val_losses.append(val_loss.item())\n",
    "\n",
    "                top_p, top_class = output.topk(1, dim=1)#get the possible class prediction\n",
    "                \n",
    "                equals = top_class == targets.view(*top_class.shape).long()\n",
    "                #print(\"top_class: \\n\",top_class.view(*targets.shape))\n",
    "                val_output.extend(top_class.view(*targets.shape))\n",
    "                accuracy += torch.mean(equals.type(torch.FloatTensor))\n",
    "                f1score += metrics.f1_score(top_class.cpu(), targets.view(*top_class.shape).long().cpu(), average='weighted')\n",
    "            \n",
    "        net.train() # reset to train mode after iterationg through validation data\n",
    "        print(batch_size)        \n",
    "        print(\"Epoch: {}/{}...\".format(e+1, epochs),\n",
    "        \"Train Loss: {:.4f}...\".format(np.mean(train_losses)),\n",
    "        \"Val Loss: {:.4f}...\".format(np.mean(val_losses)),\n",
    "        \"Val Acc: {:.4f}...\".format(accuracy/(len(X_test)//batch_size)),\n",
    "        \"F1-Score: {:.4f}...\".format(f1score/(len(X_test)//batch_size)))\n",
    "        print(\"Length of true and predict:{}/{}...\".format(len(val_target),len(val_output)))\n",
    "        cm = confusion_matrix(val_target,val_output)\n",
    "        print(classification_report(val_target,val_output,target_names = np.array(y_unique)))\n",
    "        \n",
    "        tl = np.mean(train_losses)\n",
    "        vl = np.mean(val_losses)\n",
    "        ac = accuracy/(len(X_test)//batch_size)\n",
    "        if vl < min_loss or ac>max_acc:\n",
    "            min_loss = vl\n",
    "            max_acc = ac\n",
    "            print(\"save model\")\n",
    "            torch.save(net.state_dict(),os.path.abspath(os.path.join(os.getcwd(), \"..\",\"cm_results\",\"model\"+\".pth\")))\n",
    "            print_cm(cm,e)\n",
    "        valloss.append(vl)\n",
    "        valacc.append(ac)\n",
    "        traloss.append(tl)\n",
    "    x = np.arange(epochs)\n",
    "    \n",
    "    plt.gca()\n",
    "    plt.plot(x,valloss,color='green',label='val_loss')\n",
    "    plt.plot(x,traloss,color='red',label='train_loss')\n",
    "    plt.plot(x,valacc,color='blue',label='val_acc')\n",
    "    plt.xlabel('epochs')\n",
    "    plt.savefig(os.path.abspath(os.path.join(os.getcwd(), \"..\",\"cm_results\",\"result_t.jpg\")))\n",
    "    plt.close()\n",
    "train(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
