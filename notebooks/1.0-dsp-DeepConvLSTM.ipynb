{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'wget' 不是内部或外部命令，也不是可运行的程序\n",
      "或批处理文件。\n"
     ]
    }
   ],
   "source": [
    "!wget https://archive.ics.uci.edu/ml/machine-learning-databases/00226/OpportunityUCIDataset.zip -P ../data/raw/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-2-05c2b0460174>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-2-05c2b0460174>\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    python3 ../src/data/preprocess_data.py -i  ../data/raw/OpportunityUCIDataset.zip -o ../processed/oppChallenge_gestures.data\u001b[0m\n\u001b[1;37m             ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "!mkdir ../data/processed\n",
    "!python3 ../src/data/preprocess_data.py -i  ../data/raw/OpportunityUCIDataset.zip -o ../processed/oppChallenge_gestures.data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import numpy as np\n",
    "import _pickle as cp\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import sklearn.metrics as metrics\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "#NB_SENSOR_CHANNELS = 113\n",
    "NB_SENSOR_CHANNELS = 15\n",
    "SLIDING_WINDOW_LENGTH = 50\n",
    "SLIDING_WINDOW_STEP = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# add the 'src' directory as one where we can import modules\n",
    "src_dir = os.path.join(os.getcwd(), os.pardir, 'src')\n",
    "sys.path.append(src_dir)\n",
    "\n",
    "from data.sliding_window import sliding_window"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load in Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      " ..from file C:\\Users\\Zhiha\\Documents\\file_only\\research\\tool_program\\ori\\Sensor-Based-Human-Activity-Recognition-DeepConvLSTM-Pytorch\\data\\processed\\mygestures.data\n",
      " ..reading instances: train (101668, 15), test (43573, 15)\n",
      "..part of x_train <class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def load_dataset(filename):\n",
    "    \n",
    "    with open(filename, 'rb') as f:\n",
    "        data = cp.load(f)\n",
    "    \n",
    "    X_train, y_train = data[0]\n",
    "    X_test, y_test = data[1]\n",
    "\n",
    "    print(\" ..from file {}\".format(filename))\n",
    "    print(\" ..reading instances: train {0}, test {1}\".format(X_train.shape, X_test.shape))\n",
    "\n",
    "    X_train = X_train.astype(np.float32)\n",
    "    X_test = X_test.astype(np.float32)\n",
    "    \n",
    "    print(\"..part of x_train\",type(X_train))\n",
    "    #print(X_train[:23,:2])\n",
    "    # The targets are casted to int8 for GPU compatibility.\n",
    "    y_train = y_train.astype(np.uint8)\n",
    "    y_test = y_test.astype(np.uint8)\n",
    "\n",
    "    return X_train, y_train, X_test, y_test\n",
    "\n",
    "print(\"Loading data...\")\n",
    "#X_train, y_train, X_test, y_test = load_dataset('../data/processed/oppChallenge_gestures.data')\n",
    "X_train, y_train, X_test, y_test = load_dataset('C:\\\\Users\\\\Zhiha\\\\Documents\\\\file_only\\\\research\\\\tool_program\\\\ori\\\\Sensor-Based-Human-Activity-Recognition-DeepConvLSTM-Pytorch\\\\data\\\\processed\\\\mygestures.data')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4065, 50, 15)\n",
      "[ 2  2  2  2  9  9  9 13 13 13 14 14 14 14 14 14  4  4  4  7  7  7  7  7\n",
      "  7  7  7  7  2  2  2  2  2  2  2  2  0  0  0  3  3  3  3  1  1  1 14 14\n",
      " 14 14 14 14 14 14  3  3  3  3  4  4  4  4  8  8  8  8 12 12 12 12 12 12\n",
      " 12 12 12  1  1  1  2  2  2  2  2  2  8  8  8  8 11 11 11  5  5  5  0  0\n",
      "  0  0 11 11 11  9  9  9  5  5  5  0  0  0  0  0  0  0  0  0 12 12 12 12\n",
      " 12 12 12 12 12 11 11 11 11 11 11  9  9  9  4  4  4  4 11 11 11  3  3  3\n",
      "  3 14 14 14 14 14  1  1  1  4  4  4  4  4  4  9  9 10 10 10 10 10 14 14\n",
      " 14 14 14 14  1  1  1 14 14 14 14 14 14 14 14 14  7  7  7  7  7  7  7  7\n",
      "  7  7  7  7  7  7  7 13 13 13 13 13 13 11 11 11  8  8  8  8 10 10 10  6\n",
      "  6  6  6  4  4  4  5  5  1  1  1  1  9  9  9 11 11 11 11 11  9  9  9  9\n",
      "  4  4  4 11 11 11 11  9  9  5  5  5  6  6  6 14 14 14 14 14 14  1  1 10\n",
      " 10 10 10  5  5  3  3  3  3  9  9  9 12 12 12 12 12 12 12 12 12 12 12 12\n",
      " 12 12 10 10 10  5  5  5  3  3  3  3 10 10 10 10  1  1  1 13 13 13 13  5\n",
      "  5  5 14 14 14 14  0  0  0  4  4  4  4  4  4  4  4  4 12 12 12 12 12 12\n",
      " 12 12 12  0  0  0  0  0  0  8  8  8  8  8  8  3  3  3  3 14 14 14 14 14\n",
      " 11 11 11 11 11  4  4  4  1  1  4  4  4  4 10 10 10  4  4  4  4 10 10 10\n",
      " 10 13 13 13 11 11 11 11  6  6  6 11 11 11  4  4  4  0  0  0  4  4  4  4\n",
      " 11 11 11 11 11 11  0  0  0  8  8  8  8 14 14 14 14 14 14 14 14 14 13 13\n",
      " 13 13 11 11 11 11 11 11  1  1  1  4  4  4  0  0  0 11 11 11 11 11 11  0\n",
      "  0  0  4  4  4  9  9  9  0  0  0 13 13 13 13  2  2  2  2  4  4  4  4 10\n",
      " 10 10 11 11 11 11 11  3  3  3  9  9  9  9 12 12 12 12 12 12]\n",
      " ..after sliding and reshaping, train data: inputs (4065, 50, 15), targets (4065,)\n",
      " ..after sliding and reshaping, test data : inputs (1741, 50, 15), targets (1741,)\n"
     ]
    }
   ],
   "source": [
    "assert NB_SENSOR_CHANNELS == X_train.shape[1]\n",
    "def opp_sliding_window(data_x, data_y, ws, ss):\n",
    "    data_x = sliding_window(data_x, (ws, data_x.shape[1]), (ss, 1))\n",
    "    data_y = np.asarray([[i[-1]] for i in sliding_window(data_y, ws, ss)])\n",
    "    return data_x.astype(np.float32), data_y.reshape(len(data_y)).astype(np.uint8)\n",
    "\n",
    "# Sensor data is segmented using a sliding window mechanism\n",
    "X_train, y_train = opp_sliding_window(X_train, y_train, SLIDING_WINDOW_LENGTH, SLIDING_WINDOW_STEP)\n",
    "X_test, y_test = opp_sliding_window(X_test, y_test, SLIDING_WINDOW_LENGTH, SLIDING_WINDOW_STEP)\n",
    "#print(X_train[:24,:3])\n",
    "print(X_train.shape)\n",
    "# Data is reshaped\n",
    "X_train = X_train.reshape((-1, SLIDING_WINDOW_LENGTH, NB_SENSOR_CHANNELS)) # for input to Conv1D\n",
    "X_test = X_test.reshape((-1, SLIDING_WINDOW_LENGTH, NB_SENSOR_CHANNELS)) # for input to Conv1D\n",
    "\n",
    "print(y_train[2000:2500,])\n",
    "print(\" ..after sliding and reshaping, train data: inputs {0}, targets {1}\".format(X_train.shape, y_train.shape))\n",
    "print(\" ..after sliding and reshaping, test data : inputs {0}, targets {1}\".format(X_test.shape, y_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HARModel(nn.Module):\n",
    "    \n",
    "    def __init__(self, n_hidden=128, n_layers=1, n_filters=64, \n",
    "                 n_classes=15, filter_size=5, drop_prob=0.5):\n",
    "        super(HARModel, self).__init__()\n",
    "        self.drop_prob = drop_prob\n",
    "        self.n_layers = n_layers\n",
    "        self.n_hidden = n_hidden\n",
    "        self.n_filters = n_filters\n",
    "        self.n_classes = n_classes\n",
    "        self.filter_size = filter_size\n",
    "             \n",
    "        self.conv1 = nn.Conv1d(NB_SENSOR_CHANNELS, n_filters, filter_size)\n",
    "        self.conv2 = nn.Conv1d(n_filters, n_filters, filter_size)\n",
    "        self.conv3 = nn.Conv1d(n_filters, n_filters, filter_size)\n",
    "        self.conv4 = nn.Conv1d(n_filters, n_filters, filter_size)\n",
    "        \n",
    "        self.lstm1  = nn.LSTM(n_filters, n_hidden, n_layers)\n",
    "        self.lstm2  = nn.LSTM(n_hidden, n_hidden, n_layers)\n",
    "        \n",
    "        self.fc = nn.Linear(n_hidden, n_classes)\n",
    "\n",
    "        self.dropout = nn.Dropout(drop_prob)\n",
    "    \n",
    "    def forward(self, x, hidden, batch_size):\n",
    "        \n",
    "        x = x.view(-1, NB_SENSOR_CHANNELS, SLIDING_WINDOW_LENGTH)#reshape\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = F.relu(self.conv4(x))\n",
    "        #print(x.size())\n",
    "        x = x.view(34, -1, self.n_filters)\n",
    "        x, hidden = self.lstm1(x, hidden)\n",
    "        x, hidden = self.lstm2(x, hidden)\n",
    "        \n",
    "        x = x.contiguous().view(-1, self.n_hidden)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc(x)\n",
    "        \n",
    "        out = x.view(batch_size, -1, self.n_classes)[:,-1,:]\n",
    "        \n",
    "        return out, hidden\n",
    "    \n",
    "    def init_hidden(self, batch_size):\n",
    "        ''' Initializes hidden state '''\n",
    "        # Create two new tensors with sizes n_layers x batch_size x n_hidden,\n",
    "        # initialized to zero, for hidden state and cell state of LSTM\n",
    "        weight = next(self.parameters()).data\n",
    "        '''\n",
    "        if (train_on_gpu):\n",
    "            hidden = (weight.new(self.n_layers, batch_size, self.n_hidden).zero_().cuda(),\n",
    "                  weight.new(self.n_layers, batch_size, self.n_hidden).zero_().cuda())\n",
    "        else:\n",
    "            hidden = (weight.new(self.n_layers, batch_size, self.n_hidden).zero_(),\n",
    "                      weight.new(self.n_layers, batch_size, self.n_hidden).zero_())\n",
    "        '''\n",
    "        hidden = (weight.new(self.n_layers, batch_size, self.n_hidden).zero_(),\n",
    "                      weight.new(self.n_layers, batch_size, self.n_hidden).zero_())\n",
    "        \n",
    "        return hidden\n",
    "    \n",
    "net = HARModel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize Model Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HARModel(\n",
       "  (conv1): Conv1d(15, 64, kernel_size=(5,), stride=(1,))\n",
       "  (conv2): Conv1d(64, 64, kernel_size=(5,), stride=(1,))\n",
       "  (conv3): Conv1d(64, 64, kernel_size=(5,), stride=(1,))\n",
       "  (conv4): Conv1d(64, 64, kernel_size=(5,), stride=(1,))\n",
       "  (lstm1): LSTM(64, 128)\n",
       "  (lstm2): LSTM(128, 128)\n",
       "  (fc): Linear(in_features=128, out_features=15, bias=True)\n",
       "  (dropout): Dropout(p=0.5, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def init_weights(m):\n",
    "    if type(m) == nn.LSTM:\n",
    "        for name, param in m.named_parameters():\n",
    "            if 'weight_ih' in name:\n",
    "                torch.nn.init.orthogonal_(param.data)\n",
    "            elif 'weight_hh' in name:\n",
    "                torch.nn.init.orthogonal_(param.data)\n",
    "            elif 'bias' in name:\n",
    "                param.data.fill_(0)\n",
    "    elif type(m) == nn.Conv1d or type(m) == nn.Linear:\n",
    "        torch.nn.init.orthogonal_(m.weight)\n",
    "        m.bias.data.fill_(0)\n",
    "net.apply(init_weights)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Minibatches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iterate_minibatches(inputs, targets, batchsize, shuffle=True):\n",
    "    assert len(inputs) == len(targets)\n",
    "    if shuffle:\n",
    "        indices = np.arange(len(inputs))\n",
    "        np.random.shuffle(indices)\n",
    "    for start_idx in range(0, len(inputs) - batchsize + 1, batchsize):\n",
    "        if shuffle:\n",
    "            excerpt = indices[start_idx:start_idx + batchsize]\n",
    "        else:\n",
    "            excerpt = slice(start_idx, start_idx + batchsize)\n",
    "        yield inputs[excerpt], targets[excerpt]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "## check if GPU is available\n",
    "#train_on_gpu = torch.cuda.is_available()\n",
    "#if(train_on_gpu):\n",
    "    #print('Training on GPU!')\n",
    "#else: \n",
    "    #print('No GPU available, training on CPU; consider making n_epochs very small.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1741\n",
      "10\n",
      "Epoch: 1/100... Train Loss: 2.5947... Val Loss: 2.6246... Val Acc: 0.1178... F1-Score: 0.1954...\n",
      "10\n",
      "Epoch: 2/100... Train Loss: 2.5760... Val Loss: 2.6020... Val Acc: 0.0914... F1-Score: 0.1424...\n",
      "10\n",
      "Epoch: 3/100... Train Loss: 2.3363... Val Loss: 2.1664... Val Acc: 0.3017... F1-Score: 0.3480...\n",
      "10\n",
      "Epoch: 4/100... Train Loss: 1.9589... Val Loss: 1.8099... Val Acc: 0.3994... F1-Score: 0.4396...\n",
      "10\n",
      "Epoch: 5/100... Train Loss: 1.5708... Val Loss: 1.3915... Val Acc: 0.5103... F1-Score: 0.5380...\n",
      "10\n",
      "Epoch: 6/100... Train Loss: 1.2610... Val Loss: 1.1669... Val Acc: 0.5810... F1-Score: 0.5981...\n",
      "10\n",
      "Epoch: 7/100... Train Loss: 1.0924... Val Loss: 1.1054... Val Acc: 0.6029... F1-Score: 0.6272...\n",
      "10\n",
      "Epoch: 8/100... Train Loss: 0.9773... Val Loss: 1.0205... Val Acc: 0.6178... F1-Score: 0.6393...\n",
      "10\n",
      "Epoch: 9/100... Train Loss: 0.8891... Val Loss: 0.9824... Val Acc: 0.6471... F1-Score: 0.6729...\n",
      "10\n",
      "Epoch: 10/100... Train Loss: 0.8007... Val Loss: 0.9710... Val Acc: 0.6557... F1-Score: 0.6580...\n",
      "10\n",
      "Epoch: 11/100... Train Loss: 0.7836... Val Loss: 0.9450... Val Acc: 0.6684... F1-Score: 0.6902...\n",
      "10\n",
      "Epoch: 12/100... Train Loss: 0.7336... Val Loss: 0.8426... Val Acc: 0.7006... F1-Score: 0.7164...\n",
      "10\n",
      "Epoch: 13/100... Train Loss: 0.7048... Val Loss: 0.9197... Val Acc: 0.6793... F1-Score: 0.6963...\n",
      "10\n",
      "Epoch: 14/100... Train Loss: 0.6839... Val Loss: 0.8804... Val Acc: 0.6885... F1-Score: 0.7070...\n",
      "10\n",
      "Epoch: 15/100... Train Loss: 0.6869... Val Loss: 0.7742... Val Acc: 0.7218... F1-Score: 0.7299...\n",
      "10\n",
      "Epoch: 16/100... Train Loss: 0.6852... Val Loss: 0.9889... Val Acc: 0.6644... F1-Score: 0.6845...\n",
      "10\n",
      "Epoch: 17/100... Train Loss: 0.6999... Val Loss: 0.8484... Val Acc: 0.6966... F1-Score: 0.7081...\n",
      "10\n",
      "Epoch: 18/100... Train Loss: 0.6618... Val Loss: 0.9060... Val Acc: 0.6799... F1-Score: 0.6896...\n",
      "10\n",
      "Epoch: 19/100... Train Loss: 0.6868... Val Loss: 1.0442... Val Acc: 0.6190... F1-Score: 0.6339...\n",
      "10\n",
      "Epoch: 20/100... Train Loss: 1.0670... Val Loss: 1.1788... Val Acc: 0.5787... F1-Score: 0.5939...\n",
      "10\n",
      "Epoch: 21/100... Train Loss: 0.9707... Val Loss: 1.1674... Val Acc: 0.5977... F1-Score: 0.6098...\n",
      "10\n",
      "Epoch: 22/100... Train Loss: 1.1780... Val Loss: 1.5384... Val Acc: 0.4667... F1-Score: 0.4840...\n",
      "10\n",
      "Epoch: 23/100... Train Loss: 1.8043... Val Loss: 2.4446... Val Acc: 0.1793... F1-Score: 0.2195...\n",
      "10\n",
      "Epoch: 24/100... Train Loss: 2.2881... Val Loss: 1.8279... Val Acc: 0.3655... F1-Score: 0.4217...\n",
      "10\n",
      "Epoch: 25/100... Train Loss: 1.9499... Val Loss: 1.8639... Val Acc: 0.3517... F1-Score: 0.3901...\n",
      "10\n",
      "Epoch: 26/100... Train Loss: 2.1756... Val Loss: 2.6426... Val Acc: 0.1103... F1-Score: 0.1822...\n",
      "10\n",
      "Epoch: 27/100... Train Loss: 2.6192... Val Loss: 2.6235... Val Acc: 0.0741... F1-Score: 0.1286...\n",
      "10\n",
      "Epoch: 28/100... Train Loss: 2.5918... Val Loss: 2.6142... Val Acc: 0.1057... F1-Score: 0.1653...\n",
      "10\n",
      "Epoch: 29/100... Train Loss: 2.5850... Val Loss: 2.6166... Val Acc: 0.0741... F1-Score: 0.1272...\n",
      "10\n",
      "Epoch: 30/100... Train Loss: 2.5827... Val Loss: 2.6316... Val Acc: 0.0741... F1-Score: 0.1276...\n",
      "10\n",
      "Epoch: 31/100... Train Loss: 2.5794... Val Loss: 2.6152... Val Acc: 0.0741... F1-Score: 0.1267...\n",
      "10\n",
      "Epoch: 32/100... Train Loss: 2.5791... Val Loss: 2.6280... Val Acc: 0.0741... F1-Score: 0.1285...\n",
      "10\n",
      "Epoch: 33/100... Train Loss: 2.5790... Val Loss: 2.6204... Val Acc: 0.0741... F1-Score: 0.1255...\n",
      "10\n",
      "Epoch: 34/100... Train Loss: 2.5786... Val Loss: 2.6176... Val Acc: 0.1138... F1-Score: 0.1880...\n",
      "10\n",
      "Epoch: 35/100... Train Loss: 2.5762... Val Loss: 2.6193... Val Acc: 0.0741... F1-Score: 0.1270...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-23-0ddf1963d73e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     71\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     72\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 73\u001b[1;33m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-23-0ddf1963d73e>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(net, epochs, batch_size, lr)\u001b[0m\n\u001b[0;32m     34\u001b[0m             \u001b[0mtrain_losses\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m             \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 36\u001b[1;33m             \u001b[0mopt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     37\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m         \u001b[0mval_h\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minit_hidden\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\autograd\\grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     24\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 26\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     27\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mF\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\optim\\sgd.py\u001b[0m in \u001b[0;36mstep\u001b[1;34m(self, closure)\u001b[0m\n\u001b[0;32m    104\u001b[0m                     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    105\u001b[0m                         \u001b[0mbuf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparam_state\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'momentum_buffer'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 106\u001b[1;33m                         \u001b[0mbuf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmomentum\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0md_p\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mdampening\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    107\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[0mnesterov\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    108\u001b[0m                         \u001b[0md_p\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0md_p\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbuf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmomentum\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def train(net, epochs=100, batch_size=10, lr=0.01):\n",
    "    \n",
    "    opt = torch.optim.SGD(net.parameters(), lr=lr, momentum=0.9, weight_decay=1e-4)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    #if(train_on_gpu):\n",
    "        #net.cuda()\n",
    "     \n",
    "    for e in range(epochs):\n",
    "        \n",
    "        # initialize hidden state\n",
    "        h = net.init_hidden(batch_size)         \n",
    "        train_losses = []    \n",
    "        net.train()\n",
    "        for batch in iterate_minibatches(X_train, y_train, batch_size):\n",
    "            x, y = batch\n",
    "\n",
    "            inputs, targets = torch.from_numpy(x), torch.from_numpy(y)\n",
    "\n",
    "            #if(train_on_gpu):\n",
    "            #        inputs, targets = inputs.cuda(), targets.cuda()\n",
    "\n",
    "            # Creating new variables for the hidden state, otherwise\n",
    "            # we'd backprop through the entire training history\n",
    "            h = tuple([each.data for each in h])\n",
    "            \n",
    "            # zero accumulated gradients\n",
    "            opt.zero_grad()   \n",
    "            \n",
    "            # get the output from the model\n",
    "            output, h = net(inputs, h, batch_size)\n",
    "            \n",
    "            loss = criterion(output, targets.long())\n",
    "            train_losses.append(loss.item())\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "            \n",
    "        val_h = net.init_hidden(batch_size)\n",
    "        val_losses = []\n",
    "        accuracy=0\n",
    "        f1score=0\n",
    "        net.eval()\n",
    "        with torch.no_grad():\n",
    "            for batch in iterate_minibatches(X_test, y_test, batch_size):\n",
    "                x, y = batch     \n",
    "\n",
    "                inputs, targets = torch.from_numpy(x), torch.from_numpy(y)\n",
    "\n",
    "                val_h = tuple([each.data for each in val_h])\n",
    "\n",
    "                #if(train_on_gpu):\n",
    "                #    inputs, targets = inputs.cuda(), targets.cuda()\n",
    "                    \n",
    "                output, val_h= net(inputs, val_h, batch_size)\n",
    "\n",
    "                val_loss = criterion(output, targets.long())\n",
    "                val_losses.append(val_loss.item())\n",
    "\n",
    "                top_p, top_class = output.topk(1, dim=1)\n",
    "                equals = top_class == targets.view(*top_class.shape).long()\n",
    "                accuracy += torch.mean(equals.type(torch.FloatTensor))\n",
    "                f1score += metrics.f1_score(top_class.cpu(), targets.view(*top_class.shape).long().cpu(), average='weighted')\n",
    "            \n",
    "        net.train() # reset to train mode after iterationg through validation data\n",
    "        print(batch_size)        \n",
    "        print(\"Epoch: {}/{}...\".format(e+1, epochs),\n",
    "        \"Train Loss: {:.4f}...\".format(np.mean(train_losses)),\n",
    "        \"Val Loss: {:.4f}...\".format(np.mean(val_losses)),\n",
    "        \"Val Acc: {:.4f}...\".format(accuracy/(len(X_test)//batch_size)),\n",
    "        \"F1-Score: {:.4f}...\".format(f1score/(len(X_test)//batch_size)))\n",
    "print(len(X_test))\n",
    "\n",
    "train(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
